{"title":"Coordinate System","markdown":{"yaml":{"title":"Coordinate System","format":{"html":{"toc":true,"code-fold":false}},"execute":{"eval":false,"warning":false},"jupyter":"python3","bibliography":["../references.bib"]},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nBecause of the many different data representations, dealing with coordinates in the MICrONs data is not entirely simple and it is easy to make mistakes by converting between coordinate systems incorrectly.\n\nThere are three main coordinate systems that wind up getting used:\n\n1. **Voxel coordinates** are the coordinates of a point in the original image volume.\nThese are the coordinates that are used to index into the volumes you can see in Neuroglancer, but each number has a potentially different unit.\nIn the MICrONs data, a voxel is 4 nm wide in the x and y directions, and 40 nm long in the z direction.\nThis means that a 1x1x1 micron cube would be represented by a 250x250x25 voxel span.\n*Annotations* (such as synapses) are stored in voxel coordinates.\n\n2. **Nanometer coordinates** are the coordinates of a point in the original image volume, but in nanometers.\nThis is equivalent to the voxel coordinate multiplied by the voxel resolution, with no further transformation applied.\n*Mesh and skeleton vertices* are stored in nanometer coordinates.\n\n3. **Transformed coordinates** reflect a trasnsformation that has been applied to the original image volume.\nThis transformation is a rotation to make the pia surface as flat as possible, a translation to move the pial surface to y=0, and a scaling to bring coordinates into microns.\nTransformed coordinates are convenient for more accurate computations of depth and the pia-to-white-matter axis, but are not stored by default.\nA python package `standard_transform` helps convert data to and from transformed coordinates.\n\n::: {.callout-note}\nNote that in all of these coordinate systems (including Neuroglancer), the y axis *increases* with depth. This is a standard definition when working with images, but is the opposite of what you usually think of with points.\nBecause of that, when plotting annotations or neuroanatomy in matplotlib, you will usually have to invert the y axis with `ax.invert_yaxis()`.\n:::\n\n## Standard Transform\n\n[Standard Transform](https://github.com/ceesem/standard_transform) is a python package designed to convert voxel and nanometer coordinates to transformed coordinates, with particular emphasis on the MICrONs data.\n\n### Installation\n\nStandard Transform can be installed from pip: `pip install standard_transform`\n\n### Why use Standard Transform?\n\nLet's look at the coordinates of every excitatory neuron in the MICrONs data to see why we might want to use transformed coordinates.\n\nThis is just the raw positions, converted to nanometers.\nYou can see a few aspects that might make this hard to work with.\n\nFirst, if you look along the top of the data, you can see that the pia surface is not flat.\nIn fact, there's a roughly 5 degree slope from the left to the right.\nSecond, if you look at the location of the pia surface, it's at around y = 0.4 * 10^6.\n\nNot only are these units large, the offset is arbitrary and it would make much more sense to anchor y=0 to the pial surface.\n\nLet's see how we can do this with `standard_transform`.\n\nNow you can see that the surface is much more aligned with the x-axis, and the cells in layer 1 start just below y=0.\nIn addition, the units have been converted to microns, which is much more readable and more consistent with measurements in other modalities.\n\n### How to use Standard Transform.\n\nA number of examples are available in the [standard_transform readme](https://github.com/ceesem/standard_transform).\n\n#### Transforming points\n\nThe main functions when working with point data are `transform_vx` and `transform_nm`, which transform from voxel coordinates and from nanometer coordinates respectively.\nIn the above example, you will note that because we were working with annotations, we used the voxel coordinate transform.\n\nEach of the two transforms has the same functions that can be used:\n\n* `minnie_ds.{transform}.apply(x)`: This converts an `Nx3` array of points from the original space to an `Nx3` array of transformed coordinates.\n* `minnie_ds.{transform}.apply_project(projection_axis, x)`: This converts an `Nx3` array of points from the original space to an `N`-length array of transformed coordinates, taking only values along the given axis (`x`, `y`, or `z`). This is typically done along the `y` axis to get the depth of each point.\n* `minnie_ds.{transform}.apply_dataframe(column_name, df, Optional[projection_axis])`: This takes points from a dataframe column (or collection of three dataframe columns named `{column_name}_x`, `{column_name}_y`, and `{column_name}_z`) and converts them to transformed coordinates. If `projection_axis` is given, it will only return the values along that axis.\n\nWhere `{transform}` is either `transform_vx` or `transform_nm`.\n\nYou can also invert a transformation, for example if you want to convert transformed coordinates back to voxel coordinates to view in Neuroglancer.\n\n* `minnie_ds.{transform}.invert(X)`: This maps from an Nx3 array in the *transformed space* back to the original space (voxel or nanometer coordiantes, depending on which transform you used).\n\n#### Transforming meshes and skeletons\n\nStandard transform has the capability to transform MeshParty skeletons, MeshWorks, and MeshWork annotations using these same transforms as above.\n\nFor example, to transform all the vertices of meshwork object:\n\nHowever, Meshwork objects also have annotations in dataframes as well as vertices.\nIn order to transform these points, we need to specify both the name of the dataframe table and the columns to transform as a dictionary.\nFor example, if you want to also remap the `ctr_pt_position` values from the `pre_syn` table and `post_syn` tables (which are in voxels by default), you would use:\n\nNote that without the `inplace=True` parameter, these meshwork transformations will return a new object, while if`inplace=True` the original object is modified.\n","srcMarkdownNoYaml":"\n\n## Introduction\n\nBecause of the many different data representations, dealing with coordinates in the MICrONs data is not entirely simple and it is easy to make mistakes by converting between coordinate systems incorrectly.\n\nThere are three main coordinate systems that wind up getting used:\n\n1. **Voxel coordinates** are the coordinates of a point in the original image volume.\nThese are the coordinates that are used to index into the volumes you can see in Neuroglancer, but each number has a potentially different unit.\nIn the MICrONs data, a voxel is 4 nm wide in the x and y directions, and 40 nm long in the z direction.\nThis means that a 1x1x1 micron cube would be represented by a 250x250x25 voxel span.\n*Annotations* (such as synapses) are stored in voxel coordinates.\n\n2. **Nanometer coordinates** are the coordinates of a point in the original image volume, but in nanometers.\nThis is equivalent to the voxel coordinate multiplied by the voxel resolution, with no further transformation applied.\n*Mesh and skeleton vertices* are stored in nanometer coordinates.\n\n3. **Transformed coordinates** reflect a trasnsformation that has been applied to the original image volume.\nThis transformation is a rotation to make the pia surface as flat as possible, a translation to move the pial surface to y=0, and a scaling to bring coordinates into microns.\nTransformed coordinates are convenient for more accurate computations of depth and the pia-to-white-matter axis, but are not stored by default.\nA python package `standard_transform` helps convert data to and from transformed coordinates.\n\n::: {.callout-note}\nNote that in all of these coordinate systems (including Neuroglancer), the y axis *increases* with depth. This is a standard definition when working with images, but is the opposite of what you usually think of with points.\nBecause of that, when plotting annotations or neuroanatomy in matplotlib, you will usually have to invert the y axis with `ax.invert_yaxis()`.\n:::\n\n## Standard Transform\n\n[Standard Transform](https://github.com/ceesem/standard_transform) is a python package designed to convert voxel and nanometer coordinates to transformed coordinates, with particular emphasis on the MICrONs data.\n\n### Installation\n\nStandard Transform can be installed from pip: `pip install standard_transform`\n\n### Why use Standard Transform?\n\nLet's look at the coordinates of every excitatory neuron in the MICrONs data to see why we might want to use transformed coordinates.\n\nThis is just the raw positions, converted to nanometers.\nYou can see a few aspects that might make this hard to work with.\n\nFirst, if you look along the top of the data, you can see that the pia surface is not flat.\nIn fact, there's a roughly 5 degree slope from the left to the right.\nSecond, if you look at the location of the pia surface, it's at around y = 0.4 * 10^6.\n\nNot only are these units large, the offset is arbitrary and it would make much more sense to anchor y=0 to the pial surface.\n\nLet's see how we can do this with `standard_transform`.\n\nNow you can see that the surface is much more aligned with the x-axis, and the cells in layer 1 start just below y=0.\nIn addition, the units have been converted to microns, which is much more readable and more consistent with measurements in other modalities.\n\n### How to use Standard Transform.\n\nA number of examples are available in the [standard_transform readme](https://github.com/ceesem/standard_transform).\n\n#### Transforming points\n\nThe main functions when working with point data are `transform_vx` and `transform_nm`, which transform from voxel coordinates and from nanometer coordinates respectively.\nIn the above example, you will note that because we were working with annotations, we used the voxel coordinate transform.\n\nEach of the two transforms has the same functions that can be used:\n\n* `minnie_ds.{transform}.apply(x)`: This converts an `Nx3` array of points from the original space to an `Nx3` array of transformed coordinates.\n* `minnie_ds.{transform}.apply_project(projection_axis, x)`: This converts an `Nx3` array of points from the original space to an `N`-length array of transformed coordinates, taking only values along the given axis (`x`, `y`, or `z`). This is typically done along the `y` axis to get the depth of each point.\n* `minnie_ds.{transform}.apply_dataframe(column_name, df, Optional[projection_axis])`: This takes points from a dataframe column (or collection of three dataframe columns named `{column_name}_x`, `{column_name}_y`, and `{column_name}_z`) and converts them to transformed coordinates. If `projection_axis` is given, it will only return the values along that axis.\n\nWhere `{transform}` is either `transform_vx` or `transform_nm`.\n\nYou can also invert a transformation, for example if you want to convert transformed coordinates back to voxel coordinates to view in Neuroglancer.\n\n* `minnie_ds.{transform}.invert(X)`: This maps from an Nx3 array in the *transformed space* back to the original space (voxel or nanometer coordiantes, depending on which transform you used).\n\n#### Transforming meshes and skeletons\n\nStandard transform has the capability to transform MeshParty skeletons, MeshWorks, and MeshWork annotations using these same transforms as above.\n\nFor example, to transform all the vertices of meshwork object:\n\nHowever, Meshwork objects also have annotations in dataframes as well as vertices.\nIn order to transform these points, we need to specify both the name of the dataframe table and the columns to transform as a dictionary.\nFor example, if you want to also remap the `ctr_pt_position` values from the `pre_syn` table and `post_syn` tables (which are in voxels by default), you would use:\n\nNote that without the `inplace=True` parameter, these meshwork transformations will return a new object, while if`inplace=True` the original object is modified.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"em_py_07_coordinates.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.546","theme":"cosmo","title":"Coordinate System","jupyter":"python3","bibliography":["../references.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}