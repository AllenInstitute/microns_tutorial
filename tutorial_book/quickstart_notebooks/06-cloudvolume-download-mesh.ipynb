{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c814402a-70ba-43fd-8083-ee549079e5a6",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Download Mesh (cloudvolume)\"\n",
    "aliases:\n",
    "    - programmatic_access/em_py_05_meshes.ipynb\n",
    "format: \n",
    "    html:\n",
    "        toc: true \n",
    "        code-fold: false\n",
    "        code-links:\n",
    "          - text: Download Quickstart Notebooks\n",
    "            icon: file-code\n",
    "            href: https://github.com/AllenInstitute/microns_tutorial/tree/main/tutorial_book/quickstart_notebooks\n",
    "execute:\n",
    "    eval: False\n",
    "    warning: False\n",
    "jupyter: python3\n",
    "bibliography: [../references.bib]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ccc2db-979d-43d0-a9c6-e56f1b124da0",
   "metadata": {},
   "source": [
    "## Connected morphological representations: meshes\n",
    "\n",
    "When trying to understand the fine 3d morphology of a neuron (e.g. features under 1 micron in scale), meshes are a particularly useful representation.More precisely, a mesh is a collection of vertices and faces that define a 3d surface.\n",
    "\n",
    "The meshes that one sees in Neuroglancer are available to download through the python client [cloud-volume](https://github.com/seung-lab/cloud-volume), and can be loaded for analysis and visualization in other tools.\n",
    "\n",
    "{{< include _morphological_representations.qmd >}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b724fcaa-b31f-42ed-8486-4defc7248bc1",
   "metadata": {},
   "source": [
    "## What is a mesh?\n",
    "A mesh is a set of vertices connected via triangular faces to form a 3 dimensional representation of the outer membrane of a neuron, glia or nucleus.\n",
    "\n",
    "### Meshes can either be static or dynamic:\n",
    "##### Static:\n",
    "- pros: smaller files thus easier to work with, multiple levels of detail (lod) which can be accessed (example below)\n",
    "- cons: may include false gaps and merges from self contacts, updated less frequently\n",
    "\n",
    "Example path: `precomputed://gs://iarpa_microns/minnie/minnie65/seg_m1300`\n",
    "\n",
    "##### Dynamic:\n",
    "- pros: highly detailed thus more reflective of biological reality and backed by proofreading infrastructure CAVE (Connectome Annotation Versioning Engine)\n",
    "- cons: much larger files, only one level of detail\n",
    "  \n",
    "Example path: `graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdead3f5-6f3f-4e04-a84a-c31cc40343e8",
   "metadata": {},
   "source": [
    "## Cloud-Volume for downloading meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a3fe9-eb66-4480-9a0d-a6de25d06f3b",
   "metadata": {},
   "source": [
    "CloudVolume is a serverless Python client for random access reading and writing of [Neuroglancer](https://github.com/google/neuroglancer/) volumes in [\"Precomputed\"](https://github.com/google/neuroglancer/tree/master/src/datasource/precomputed#readme) format, a set of representations for arbitrarily large volumetric images, meshes, and skeletons.\n",
    "\n",
    "Precomputed volumes are typically stored on AWS S3, Google Storage, or locally. CloudVolume can read and write to these object storage providers given a service account token with appropriate permissions. However, these volumes can be stored on any service, including an ordinary webserver or local filesystem, that supports key-value access.\n",
    "\n",
    "[cloud-volume](https://github.com/seung-lab/cloud-volume/) is the mechanism for many programmatic data queries, and integrates heavily with the CAVE ecosystem but is distinct. You can install cloud-volume with:\n",
    "\n",
    "```python\n",
    "pip install cloud-volume\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9331e152-e82c-4e20-b679-8cd22162e0f3",
   "metadata": {},
   "source": [
    "The **Connectome Annotation Versioning Engine (CAVE)** is a suite of tools developed at the Allen Institute and Seung Lab to manage large connectomics data.  \n",
    "\n",
    "::: {.callout-important}\n",
    "## Initial Setup\n",
    "Before using any programmatic access to the data, [you first need to set up your CAVEclient token](01-caveclient-setup.html). When `CAVEclient` saves the token to your local machine, `cloudvolume` will access the same token.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd4bec-cbbd-4d17-81e0-fae562710eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient\n",
    "from cloudvolume import CloudVolume\n",
    "\n",
    "datastack_name = 'minnie65_public'\n",
    "client = CAVEclient(datastack_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a9cc3-f179-4296-abf1-041c444eda62",
   "metadata": {},
   "source": [
    "The datastack includes information about the segmentation source, and can provide that information when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3b135b-a385-4b13-9c4b-7e0e646ef7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.info.segmentation_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d6cce-4654-40e1-9da4-e341a435017f",
   "metadata": {},
   "source": [
    "Note that this is the same as the **dynamic** segmentation path above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34045fbc-160e-4af0-a1e0-2eb9f77a7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be used to initialize a cloudvolume object\n",
    "cv = CloudVolume(client.info.segmentation_source(), progress=False, use_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203fbdb-ad40-4b84-9c6e-dda492a03285",
   "metadata": {},
   "source": [
    "### Examples from the cloudvolume README:\n",
    "\n",
    "```python\n",
    "cv.mesh.get(12345) # return the mesh as vertices and faces instead of writing to disk\n",
    "cv.mesh.get([ 12345, 12346 ]) # return these two segids fused into a single mesh\n",
    "cv.mesh.get([ 12345, 12346 ], fuse=False) # return { 12345: mesh, 12346: mesh }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb343bb-3386-4ed0-8369-9e1620954421",
   "metadata": {},
   "source": [
    "### Download dynamic mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554e7b5-e1aa-4264-bf26-62bc1b7d041a",
   "metadata": {},
   "source": [
    "Given a root_id, __CloudVolume__ can be used to retrieve the mesh. \n",
    "`cloudvolume.mesh.get()` returns a dictionary with the neuron segment id as the key and the mesh as the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58151c04-8f58-42a4-a373-9c111d9ab74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n",
      "CPU times: total: 48 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "# specify the materialization version, for consistency across time\",\n",
    "client.version = 1300\n",
    "\n",
    "# Example: pyramidal cell in v1300\n",
    "example_cell_id = 864691135572530981\n",
    "%time mesh = cv.mesh.get(example_cell_id)[example_cell_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6f810-4387-4599-a582-01d9e6e9fecd",
   "metadata": {},
   "source": [
    "### Download static mesh \n",
    "The meshes that are available in the visualization on [microns-explorer.org](https://www.microns-explorer.org/gallery-mm3) are fast to load because they are static and have been downsampled at multiple resolutions. However, this comes with the drawback of being less biologically accurate.\n",
    "\n",
    "Level of detail is controlled with optional argument, where `lod=0` is the highest level of detail\n",
    "\n",
    "we can access one of these downsampled static meshes by setting the path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afd27fc-be9a-4840-8811-b97a80f998fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg_m1300\", use_https=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2e2f4d-0142-4cd9-8614-07c7ae9e01e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 1.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# the cloud volume interface is the same but it is a faster initial download \n",
    "%time mesh = cv.mesh.get(example_cell_id, lod=3)[example_cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c0f514-9e02-4d2e-aed9-e0a074d210e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56938, 3), (99936, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see the meshes aren't exactly the same as before. They because they have not been downsampled\n",
    "mesh.vertices.shape, mesh.faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afd4dc-af01-4468-98d5-a61264427bd0",
   "metadata": {},
   "source": [
    "In addition, the Static meshes are available in 3 levels of detail, this covers two orders of magnitude of detail\n",
    "which is what neuroglancer leverages to efficiently load the data at the resolution necessary to render the current scene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d27eeb3-5d72-41c7-b668-2ce23fa693cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 0: n_verts: 5231141 n_faces: 10291430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 1: n_verts: 1457607 n_faces: 2828410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 2: n_verts: 253583 n_faces: 474769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level of detail 3: n_verts: 56938 n_faces: 99936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for lod in range(4):\n",
    "    mesh = mesh = cv.mesh.get(example_cell_id, lod=lod)[example_cell_id]\n",
    "    print(f\"level of detail {lod}: n_verts: {mesh.vertices.shape[0]} n_faces: {mesh.faces.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ee47c-56c0-4cfc-b074-f115ef3f17e0",
   "metadata": {},
   "source": [
    "The returned mesh includes:\n",
    "* vertices : Nx3 [x, y, z] positions in nm\n",
    "* faces: Kx3 [i, j, k] indices into vertices that describe the triangular meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425132d-4196-4add-a64f-f2469704078a",
   "metadata": {},
   "source": [
    "## MeshParty for processing mesh objects\n",
    "\n",
    "The [Meshparty](https://github.com/CAVEconnectome/MeshParty), which is a python package to work with meshes, designed around use cases for analyzing neuronal morphology.\n",
    "\n",
    "```python\n",
    "pip install meshparty\n",
    "```\n",
    "\n",
    "The MeshParty object has more useful properties and attributes\n",
    "such as:\n",
    "* a scipy.csgraph sparse graph object (mesh.csgraph)\n",
    "* a networkx graph object (mesh.nxgraph) \n",
    "\n",
    "Read more about what you can do with MeshParty on its [Documentation](https://meshparty.readthedocs.io/en/latest/?badge=latest).\n",
    "\n",
    "In particular it lets you associate _skeletons_, and _annotations_ onto the mesh into a \"meshwork\" object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b011ef59-ec37-43a9-9196-dc631c8ba225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Meshes: 100%|████████████████████████████████████████████████████████████████| 1/1 [01:01<00:00, 61.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from meshparty import trimesh_io\n",
    "from caveclient import CAVEclient\n",
    "client = CAVEclient('minnie65_public')\n",
    "\n",
    "mm = trimesh_io.MeshMeta(\n",
    "  cv_path=client.info.segmentation_source(),\n",
    "  disk_cache_path=\"meshes\",\n",
    ")\n",
    "\n",
    "example_cell_id = 864691135572530981\n",
    "mesh = mm.mesh(seg_id=example_cell_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f16024-3a7b-4312-b639-5f076467df2d",
   "metadata": {},
   "source": [
    "One convenience of using the `MeshMeta` approach is that if you have already downloaded a mesh for with a given root id, it will be loaded from disk rather than re-downloaded.\n",
    "\n",
    "If you have to download many meshes, it is somewhat faster to use the bulk `download_meshes` function and use multiple threads via the `n_threads` argument. If you download them to the same folder used for the MeshMeta object, they can be loaded through the same interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaae6a2-00a4-4797-8ecf-eded431e82c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "root_ids = [864691135572530981, 864691135014128278, 864691134940133219]\n",
    "mm = trimesh_io.download_meshes(\n",
    "    seg_ids=root_ids,\n",
    "    target_dir='meshes',\n",
    "    cv_path=client.info.segmentation_source(),\n",
    "    n_threads=4, # Or whatever value you choose above one but less than the number of cores on your computer\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792e9f1-6027-45aa-a8bc-a6407d2796c7",
   "metadata": {},
   "source": [
    "::: {.callout-caution}\n",
    "## File size\n",
    "Meshes can be hundresds of megabytes in size, so be careful about downloading too many if the internet is not acting well or your computer doesn't have much disk space!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f3b79-73fe-4c2b-8591-c58c6a566a12",
   "metadata": {},
   "source": [
    "### Healing Mesh Gaps\n",
    "![Example of a continuous neuron whose mesh has a gap](../img/mesh-discontinuity.png)\n",
    "\n",
    "Many meshes are not actually fully continuous due to small gaps in the segmentation.\n",
    "However, information collected during proofreading allows one to partially repair these gaps by adding in links where the segmentation was merged across a small gap.\n",
    "If you are just visualizaing a mesh, these gaps are not a problem, but if you want to do analysis on the mesh, you will want to heal these gaps.\n",
    "Conveniently, there's a function to do this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2435852-76d9-43d1-bf77-0c2b9d1e9e53",
   "metadata": {},
   "source": [
    "```python\n",
    "mesh.add_link_edges(\n",
    "    seg_id=example_cell_id, # This needs to be the same as the root id used to download the mesh\n",
    "    client=client.chunkedgraph,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ef552-814f-484d-95ad-bac637921ef5",
   "metadata": {},
   "source": [
    "### Properties\n",
    "\n",
    "Meshes have a large number of properties, many of which come from being based on the [Trimesh](https://trimsh.org/) library's mesh format, and others being specific to MeshParty.\n",
    "\n",
    "Several of the most important properties are:\n",
    "\n",
    "* `mesh.vertices` : An `N x 3` list of vertices and their 3d location in nanometers, where `N` is the number of vertices.\n",
    "* `mesh.faces` : An `P x 3` list of integers, with each row specifying a triangle of connected vertex indices.\n",
    "* `mesh.edges` : An `M x 2` list of integers, with each row specifying a pair of connected vertex indices based off of faces.\n",
    "* `mesh.edges` : An `M x 2` list of integers, with each row specifying a pair of connected vertex indices based off of faces.\n",
    "* `mesh.link_edges` : An `M_l x 2` list of integers, with each row specifying a pair of \"link edges\" that were used to heal gaps based on proofreading edits.\n",
    "* `mesh.graph_edges` : An `(M+M_l) x 2` list of integers, with each row specifying a pair of graph edges, which is the collection of both `mesh.edges` and `mesh.link_edges`.\n",
    "* `mesh.csgraph` : A [Scipy Compressed Sparse Graph](https://docs.scipy.org/doc/scipy/reference/sparse.csgraph.html) representation of the mesh as an `NxN` graph of vertices connected to one another using graph edges and with edge weights being the distance between vertices. This is particularly useful for computing shortest paths between vertices.\n",
    "\n",
    "::: {.callout-warning}\n",
    "MICrONs meshes are not generally \"watertight\", a property that would enable a number of properties to be computed natively by Trimesh. Because of this, Trimesh-computed properties relating to solid forms or volumes like `mesh.volume` or `mesh.center_mass` do not have sensible values and other approaches should be taken. Unfortunately, because of the Trimesh implementation of these properties it is up to the user to be aware of this issue.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc44945-c804-4e17-ae66-6b85f40d83a2",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "There are a variety of tools for visualizing meshes in python.\n",
    "MeshParty interfaces with VTK, a powerful but complex data visualization library that does not always work well in python.\n",
    "The basic pattern for MeshParty's VTK integration is to create one or more \"actors\" from the data, and then pass those to a renderer that can be displayed in an interactive approach.\n",
    "The following code snippet shows how to visualize a mesh using this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51662c-786b-4d20-9dc7-5c550e144013",
   "metadata": {},
   "source": [
    "```python\n",
    "mesh_actor = trimesh_vtk.mesh_actor(\n",
    "  mesh,\n",
    "  color=(1,0,0),\n",
    "  opacity=0.5,\n",
    ")\n",
    "trimesh_vtk.render_actors([mesh_actor])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f491e49-c8e7-4bcf-9cec-47a5dc05f09c",
   "metadata": {},
   "source": [
    "Note that by default, neurons will appear upside down because the coordinate system of the dataset has the y-axis value increasing along the \"downward\" pia to white matter axis.\n",
    "\n",
    "More documentation on the MeshParty VTK visualization can be [found here](https://meshparty.readthedocs.io/en/latest/source/meshparty.html).\n",
    "\n",
    "Other tools worth exploring are:\n",
    "\n",
    "* [PyVista](https://docs.pyvista.org/)\n",
    "* [Polyscope](https://polyscope.run/)\n",
    "* [Vedo](https://vedo.embl.es/)\n",
    "* [MeshLab](https://www.meshlab.net/)\n",
    "* If you have some existing experience, [Blender](https://www.blender.org/) (see Blender integration by our friends behind [Navis](https://navis.readthedocs.io/en/latest/source/blender.html), a fly-focused framework analyzing connectomics data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7def6cd-1230-48c3-991f-ef7bae98f6d3",
   "metadata": {},
   "source": [
    "### Masking\n",
    "\n",
    "One of the most common operations on meshes is to mask them to a particular region of interest.\n",
    "This can be done by \"masking\" the mesh with a boolean array of length `N` where `N` is the number of vertices in the mesh, with `True` where the vertex should be kept and `False` where it should be omitted.\n",
    "There are several convenience functions to generate common masks in the [Mesh Filters](https://meshparty.readthedocs.io/en/latest/source/meshparty.html#module-meshparty.mesh_filters) module.\n",
    "\n",
    "In the following example, we will first mask out all vertices that aren't part of the largest connected component of the mesh (i.e. get rid of floating vertices that might arise due to internal surfaces) and then mask out all vertices that are more than 20,000 nm away from the soma center."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0965890-7c09-4ee1-9d23-c8eee8d83c7e",
   "metadata": {},
   "source": [
    "```python\n",
    "from meshparty import mesh_filters\n",
    "\n",
    "root_id =864691134940133219 \n",
    "root_point = client.materialize.tables.nucleus_detection_v0(pt_root_id=root_id).query()['pt_position'].values[0] * [4,4,40]  # Convert the nucleus location from voxels to nanometers via the data resolution.\n",
    "\n",
    "mesh = mm.mesh(seg_id=root_id)\n",
    "# Heal gaps in the mesh\n",
    "mesh.add_link_edges(\n",
    "    seg_id=864691134940133219,\n",
    "    client=client.chunkedgraph,\n",
    ")\n",
    "\n",
    "# Generate and use the largest component mask\n",
    "comp_mask = mesh_filters.filter_largest_component(mesh)\n",
    "mask_filt = mesh.apply_mask(comp_mask)\n",
    "\n",
    "soma_mask = mesh_filters.filter_spatial_distance_from_points(\n",
    "    mask_filt,\n",
    "    root_point,\n",
    "    20_000, # Note that this is in nanometers\n",
    ")\n",
    "mesh_soma = mesh.apply_mask(soma_mask)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97524052-fd81-417f-89b4-1e58e60d1c63",
   "metadata": {},
   "source": [
    "This resulting mesh is just a small cutout around the soma.\n",
    "![Soma cutout from a full-neuron mesh](../img/soma_mesh_cutout.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microns2025",
   "language": "python",
   "name": "microns2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
